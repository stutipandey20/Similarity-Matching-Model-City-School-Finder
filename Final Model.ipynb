{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f31d99df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 5 similar schools with \"Great Hearts Academies - Anthem Prep\" using cosine similarity are:\n",
      "1. Boulder Creek High School\n",
      "2. Great Hearts Academies - Archway Veritas\n",
      "3. Great Hearts Academies - North Phoenix Prep\n",
      "4. Great Hearts Academies - Archway Chandler\n",
      "5. Basis Phoenix\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cosine similarity\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('Data_After_Transformation.csv')\n",
    "\n",
    "features = data[['Zip Code', 'Student Enrollment',\n",
    "       'State Wide Assessment Results - 2023 : ELA (English Language Arts) : ALL ENROLLED - Minimally Proficient(%)',\n",
    "       'State Wide Assessment Results - 2023 : ELA (English Language Arts) : ALL ENROLLED - Partially Proficient(%)',\n",
    "       'State Wide Assessment Results - 2023 : ELA (English Language Arts) : ALL ENROLLED - Proficient(%)',\n",
    "       'State Wide Assessment Results - 2023 : ELA (English Language Arts) : ALL ENROLLED - Highly Proficient(%)',\n",
    "       'State Wide Assessment Results - 2023 All:MATH : ALL ENROLLED - Minimally Proficient(%)',\n",
    "       'State Wide Assessment Results - 2023 All:MATH : ALL ENROLLED - Partially Proficient(%)',\n",
    "       'State Wide Assessment Results - 2023 All:MATH : ALL ENROLLED - Proficient(%)',\n",
    "       'State Wide Assessment Results - 2023 All:MATH : ALL ENROLLED - Highly Proficient(%)',\n",
    "       'End of Year Promotion (%)', 'American Indian/ Alaska Native', 'Asian',\n",
    "       'Black', 'Hispanic', 'Native Hawaiian/ Pacific Islander', 'White',\n",
    "       'Two or More Races', 'Male', 'Female', 'Grade Levels', 'County',\n",
    "       'School Type', 'Anthem', 'Avondale', 'Buckeye', 'Chandler', 'El Mirage',\n",
    "       'Fountain Hills', 'Gila Bend', 'Gilbert', 'Glendale', 'Goodyear',\n",
    "       'Highley', 'Laveen', 'Mesa', 'Peoria', 'Phoenix', 'Queen Creek',\n",
    "       'Scottsdale', 'Surprise', 'Tempe', 'Tolleson', 'Tonopah', 'Wickenburg']].values\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Calculate pairwise cosine similarity\n",
    "similarity_matrix = cosine_similarity(features_scaled)\n",
    "\n",
    "# Function to find similar schools\n",
    "def find_similar_schools(target_school_name, similarity_matrix, data, top_n=5):\n",
    "    # Find the index of the target school\n",
    "    target_school_index = data.index[data['School'] == target_school_name].tolist()[0]\n",
    "    \n",
    "    # Get similarity scores for the target school\n",
    "    similarity_scores = similarity_matrix[target_school_index]\n",
    "    \n",
    "    # Sort indices based on similarity scores (excluding the target school itself)\n",
    "    similar_school_indices = similarity_scores.argsort()[::-1][1:top_n+1]\n",
    "    \n",
    "    # Get the names of similar schools\n",
    "    similar_schools = data.iloc[similar_school_indices]['School'].tolist()\n",
    "    \n",
    "    return similar_schools\n",
    "\n",
    "# Example usage: Find top 5 similar schools for a given target school\n",
    "target_school_index = 1 \n",
    "target_school_name = data.loc[target_school_index, 'School'] \n",
    "similar_schools = find_similar_schools(target_school_name, similarity_matrix, data)\n",
    "print(f\"top 5 similar schools with \\\"{target_school_name}\\\" using cosine similarity are:\")\n",
    "for i, school in enumerate(similar_schools, 1):\n",
    "    print(f\"{i}. {school}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ed97df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 5 similar schools with \"Great Hearts Academies - Anthem Prep\" using Jaccard similarity are:\n",
      "1. Great Hearts Academies - Archway Chandler\n",
      "2. Great Hearts Academies - Archway Veritas\n",
      "3. Great Hearts Academies - Scottsdale Prep\n",
      "4. Boulder Creek High School\n",
      "5. Santan Junior High School\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stutipandey/anaconda3/lib/python3.11/site-packages/sklearn/metrics/pairwise.py:2181: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# Jaccard Similarity\n",
    "\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.preprocessing import binarize\n",
    "\n",
    "# Function to compute similarity scores using Jaccard similarity\n",
    "def compute_similarity_scores_jaccard(features, target_index):\n",
    "    # Binarize the features matrix\n",
    "    binary_features = binarize(features)\n",
    "\n",
    "    # Extract binary features of the target school\n",
    "    target_features = binary_features[target_index]\n",
    "\n",
    "    # Compute pairwise Jaccard distances\n",
    "    distances = pairwise_distances(binary_features, [target_features], metric='jaccard')\n",
    "\n",
    "    # Convert distances to similarity scores\n",
    "    similarity_scores = 1 - distances.flatten()\n",
    "\n",
    "    return similarity_scores\n",
    "\n",
    "# Example usage\n",
    "target_school_index = 1 \n",
    "similarity_scores_jaccard = compute_similarity_scores_jaccard(features_scaled, target_school_index)\n",
    "\n",
    "# Rank schools based on Jaccard similarity scores\n",
    "sorted_indices_jaccard = sorted(range(len(similarity_scores_jaccard)), key=lambda i: similarity_scores_jaccard[i], reverse=True)\n",
    "top_similar_schools_jaccard = sorted_indices_jaccard[1:6]  # Exclude the target school itself\n",
    "\n",
    "target_school_name = data.loc[target_school_index, 'School']\n",
    "\n",
    "# Print top similar schools using Jaccard similarity\n",
    "print(f\"top 5 similar schools with \\\"{target_school_name}\\\" using Jaccard similarity are:\")\n",
    "for i, idx in enumerate(top_similar_schools_jaccard, 1):\n",
    "    school_name = data.iloc[idx]['School']\n",
    "    print(f\"{i}. {school_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0e8560a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 5 similar schools with \"Great Hearts Academies - Anthem Prep\" using Euclidean distance are:\n",
      "1. Boulder Creek High School\n",
      "2. Great Hearts Academies - Archway Veritas\n",
      "3. Great Hearts Academies - North Phoenix Prep\n",
      "4. Great Hearts Academies - Veritas Prep\n",
      "5. Basis Mesa\r\n"
     ]
    }
   ],
   "source": [
    "# Euclidean Distance\n",
    "\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "# Function to compute similarity scores using Euclidean distance\n",
    "def compute_similarity_scores_euclidean(features, target_index):\n",
    "    target_features = features[target_index]\n",
    "    similarity_scores = []\n",
    "\n",
    "    for feature in features:\n",
    "        # Compute Euclidean distance\n",
    "        euclidean_dist = euclidean_distances([target_features], [feature])[0][0]\n",
    "\n",
    "        # Convert distance to similarity score (inverse of distance)\n",
    "        similarity_score = 1 / (1 + euclidean_dist)  # Adjust to your preference\n",
    "\n",
    "        similarity_scores.append(similarity_score)\n",
    "\n",
    "    return similarity_scores\n",
    "\n",
    "# Example usage\n",
    "target_school_index = 1 \n",
    "similarity_scores_euclidean = compute_similarity_scores_euclidean(features_scaled, target_school_index)\n",
    "\n",
    "# Rank schools based on Euclidean similarity scores\n",
    "sorted_indices_euclidean = sorted(range(len(similarity_scores_euclidean)), key=lambda i: similarity_scores_euclidean[i], reverse=True)\n",
    "top_similar_schools_euclidean = sorted_indices_euclidean[1:6]  # Exclude the target school itself\n",
    "\n",
    "target_school_name = data.loc[target_school_index, 'School']\n",
    "\n",
    "# Print top similar schools using Euclidean distance\n",
    "print(f\"top 5 similar schools with \\\"{target_school_name}\\\" using Euclidean distance are:\")\n",
    "for i, idx in enumerate(top_similar_schools_euclidean, 1):\n",
    "    school_name = data.iloc[idx]['School']\n",
    "    print(f\"{i}. {school_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "861fab79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 similar schools to Great Hearts Academies - Anthem Prep using KNN:\n",
      "1. Sossaman Middle School\n",
      "2. Highland Jr High School\n",
      "3. Stapley Junior High School\r\n",
      "4. Great Hearts Academies - Scottsdale Prep\n",
      "5. Great Hearts Academies - Veritas Prep\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('Data_After_Transformation.csv')\n",
    "\n",
    "# Fit the KNN model\n",
    "k = 6  # Number of neighbors to consider\n",
    "knn_model = NearestNeighbors(n_neighbors=k, algorithm='auto', metric='euclidean')\n",
    "knn_model.fit(features)\n",
    "\n",
    "# Function to find similar schools\n",
    "def find_similar_schools(target_school_index, data, top_n=5):\n",
    "    # Find k-nearest neighbors\n",
    "    distances, indices = knn_model.kneighbors([features[target_school_index]])\n",
    "    \n",
    "    # Get the indices of similar schools\n",
    "    similar_school_indices = indices[0][1:]  # Exclude the target school itself\n",
    "    \n",
    "    # Get the names of similar schools\n",
    "    similar_schools = data.iloc[similar_school_indices]['School'].tolist()\n",
    "    \n",
    "    return similar_schools\n",
    "\n",
    "# Example usage: Find top 5 similar schools for a given target school\n",
    "target_school_index = 1  # Index of the target school in the dataset\n",
    "target_school_name = data.loc[target_school_index, 'School']  # Get the name of the target school\n",
    "similar_schools = find_similar_schools(target_school_index, data)\n",
    "print(f\"Top 5 similar schools to {target_school_name} using KNN:\")\n",
    "for i, school in enumerate(similar_schools, 1):\n",
    "    print(f\"{i}. {school}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "468a1591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 similar schools to Great Hearts Academies - Anthem Prep using SVM:\n",
      "1. Rhodes Junior High School\r\n",
      "2. Metropolitan Arts Institute\n",
      "3. Mesa Distance Learning Program\r\n",
      "4. East Valley High School\n",
      "5. Ombudsman - Charter Northeast\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('Data_After_Transformation.csv')\n",
    "\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Train the SVM model\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(features_scaled, data['School'])\n",
    "\n",
    "# Function to find similar schools using SVM\n",
    "def find_similar_schools_svm(target_school_index, data, features_scaled, svm_model, top_n=5):\n",
    "    # Get the decision function values for all schools\n",
    "    decision_function_values = svm_model.decision_function(features_scaled)\n",
    "    \n",
    "    # Calculate the distance of each school from the decision boundary\n",
    "    distances = abs(decision_function_values)\n",
    "    \n",
    "    # Sort indices based on distance (excluding the target school itself)\n",
    "    sorted_indices = distances.argsort()\n",
    "    similar_school_indices = sorted_indices[sorted_indices != target_school_index][:top_n]\n",
    "    \n",
    "    # Get the names of similar schools\n",
    "    similar_schools = data.iloc[similar_school_indices]['School'].tolist()\n",
    "    \n",
    "    return similar_schools\n",
    "\n",
    "# Example usage: Find top 5 similar schools for a given target school using SVM\n",
    "target_school_index = 1  # Index of the target school in the dataset\n",
    "target_school_name = data.loc[target_school_index, 'School']  # Get the name of the target school\n",
    "similar_schools_svm = find_similar_schools_svm(target_school_index, data, features_scaled, svm_model)\n",
    "print(f\"Top 5 similar schools to {target_school_name} using SVM:\")\n",
    "for i, school in enumerate(similar_schools_svm, 1):\n",
    "    print(f\"{i}. {school}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6075167d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 similar schools to Great Hearts Academies - Anthem Prep using Decision Trees:\n",
      "1. Boulder Creek High School\n",
      "2. Willow Canyon High School\n",
      "3. Imagine Prep Surprise\n",
      "4. Valley Vista High School\n",
      "5. Arizona Charter Academy\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('Data_After_Transformation.csv')\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Train the Decision Tree model\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(features_scaled, data['School'])\n",
    "\n",
    "# Function to find similar schools using Decision Trees\n",
    "def find_similar_schools_dt(target_school_index, data, features_scaled, dt_model, top_n=5):\n",
    "    # Get the feature values for the target school\n",
    "    target_school_features = [features_scaled[target_school_index]]\n",
    "    \n",
    "    # Predict the class probabilities for all schools\n",
    "    class_probabilities = dt_model.predict_proba(features_scaled)\n",
    "    \n",
    "    # Calculate the Euclidean distance between the target school and all other schools\n",
    "    distances = ((class_probabilities - dt_model.predict_proba(target_school_features))**2).sum(axis=1)\n",
    "    \n",
    "    # Sort indices based on distance (excluding the target school itself)\n",
    "    sorted_indices = distances.argsort()\n",
    "    similar_school_indices = sorted_indices[sorted_indices != target_school_index][:top_n]\n",
    "    \n",
    "    # Get the names of similar schools\n",
    "    similar_schools = data.iloc[similar_school_indices]['School'].tolist()\n",
    "    \n",
    "    return similar_schools\n",
    "\n",
    "# Example usage: Find top 5 similar schools for a given target school using Decision Trees\n",
    "target_school_index = 1  # Index of the target school in the dataset\n",
    "target_school_name = data.loc[target_school_index, 'School']  # Get the name of the target school\n",
    "similar_schools_dt = find_similar_schools_dt(target_school_index, data, features_scaled, dt_model)\n",
    "print(f\"Top 5 similar schools to {target_school_name} using Decision Trees:\")\n",
    "for i, school in enumerate(similar_schools_dt, 1):\n",
    "    print(f\"{i}. {school}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7727045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar schools using cosine similarity:\n",
      "1. Great Hearts Academies - Anthem Prep\n",
      "2. Red Mountain High School\r\n",
      "3. Desert Vista High School\n",
      "4. Liberty High School\r\n",
      "5. Mountain View High School\n",
      "\n",
      "Similar schools using Euclidean distance:\n",
      "1. Great Hearts Academies - Anthem Prep\n",
      "2. Greenway, High School\n",
      "3. Moon Valley High School\n",
      "4. Red Mountain High School\r\n",
      "5. Chaparral High School\n"
     ]
    }
   ],
   "source": [
    "# printing the results for Euclidean and Cosine\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import jaccard_score\n",
    "from scipy.spatial.distance import euclidean\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('Data_After_Transformation.csv')\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Function to compute similarity scores using multiple techniques\n",
    "def compute_similarity_scores(features, target_index):\n",
    "    target_features = features[target_index]\n",
    "    cosine_similarity_scores = []\n",
    "    jaccard_similarity_scores = []\n",
    "    euclidean_distances = []\n",
    "\n",
    "    for feature in features:\n",
    "        # Compute cosine similarity\n",
    "        cosine_sim = cosine_similarity([target_features], [feature])[0][0]\n",
    "        cosine_similarity_scores.append(cosine_sim)\n",
    "\n",
    "        # Compute Euclidean distance\n",
    "        euclidean_dist = euclidean(target_features, feature)\n",
    "        euclidean_distances.append(euclidean_dist)\n",
    "\n",
    "    return cosine_similarity_scores, euclidean_distances\n",
    "\n",
    "# Example usage\n",
    "target_school_index = 0  # Index of the target school\n",
    "cosine_similarity_scores, euclidean_distances = compute_similarity_scores(features_scaled, target_school_index)\n",
    "\n",
    "# Rank schools based on cosine similarity scores\n",
    "sorted_indices_cosine = sorted(range(len(cosine_similarity_scores)), key=lambda i: cosine_similarity_scores[i], reverse=True)\n",
    "top_similar_schools_cosine = sorted_indices_cosine[1:6]  # Exclude the target school itself\n",
    "\n",
    "# Rank schools based on Euclidean distances\n",
    "sorted_indices_euclidean = sorted(range(len(euclidean_distances)), key=lambda i: euclidean_distances[i])\n",
    "top_similar_schools_euclidean = sorted_indices_euclidean[1:6]  # Exclude the target school itself\n",
    "\n",
    "# Print top similar schools using cosine similarity\n",
    "print(\"Similar schools using cosine similarity:\")\n",
    "for i, idx in enumerate(top_similar_schools_cosine, 1):\n",
    "    school_name = data.iloc[idx]['School']\n",
    "    print(f\"{i}. {school_name}\")\n",
    "\n",
    "# Print top similar schools using Euclidean distance\n",
    "print(\"\\nSimilar schools using Euclidean distance:\")\n",
    "for i, idx in enumerate(top_similar_schools_euclidean, 1):\n",
    "    school_name = data.iloc[idx]['School']\n",
    "    print(f\"{i}. {school_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab7c03a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy for Cosine Similarity: 0.24\n",
      "Average Accuracy for Euclidean Distance: 0.32\n"
     ]
    }
   ],
   "source": [
    "# Getting model accuracy for Euclidean & Cosine\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial.distance import euclidean\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('Data_After_Transformation.csv')\n",
    "\n",
    "# Select features\n",
    "features = data[['Zip Code', 'Student Enrollment',\n",
    "                 'State Wide Assessment Results - 2023 : ELA (English Language Arts) : ALL ENROLLED - Minimally Proficient(%)',\n",
    "                 'State Wide Assessment Results - 2023 : ELA (English Language Arts) : ALL ENROLLED - Partially Proficient(%)',\n",
    "                 'State Wide Assessment Results - 2023 : ELA (English Language Arts) : ALL ENROLLED - Proficient(%)',\n",
    "                 'State Wide Assessment Results - 2023 : ELA (English Language Arts) : ALL ENROLLED - Highly Proficient(%)',\n",
    "                 'State Wide Assessment Results - 2023 All:MATH : ALL ENROLLED - Minimally Proficient(%)',\n",
    "                 'State Wide Assessment Results - 2023 All:MATH : ALL ENROLLED - Partially Proficient(%)',\n",
    "                 'State Wide Assessment Results - 2023 All:MATH : ALL ENROLLED - Proficient(%)',\n",
    "                 'State Wide Assessment Results - 2023 All:MATH : ALL ENROLLED - Highly Proficient(%)',\n",
    "                 'End of Year Promotion (%)']].values\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Function to compute similarity scores using cosine similarity and Euclidean distance\n",
    "def compute_similarity_scores(features, target_index):\n",
    "    target_features = features[target_index]\n",
    "    cosine_similarity_scores = []\n",
    "    euclidean_distances = []\n",
    "\n",
    "    for feature in features:\n",
    "        # Compute cosine similarity\n",
    "        cosine_sim = cosine_similarity([target_features], [feature])[0][0]\n",
    "        cosine_similarity_scores.append(cosine_sim)\n",
    "\n",
    "        # Compute Euclidean distance\n",
    "        euclidean_dist = euclidean(target_features, feature)\n",
    "        euclidean_distances.append(euclidean_dist)\n",
    "\n",
    "    return cosine_similarity_scores, euclidean_distances\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "k = 5\n",
    "\n",
    "# Initialize KFold cross-validator\n",
    "kf = KFold(n_splits=k)\n",
    "\n",
    "# Initialize lists to store evaluation metrics\n",
    "cosine_similarity_accuracy = []\n",
    "euclidean_distance_accuracy = []\n",
    "\n",
    "# Iterate over each fold\n",
    "for train_index, test_index in kf.split(features_scaled):\n",
    "    # Split data into training and testing sets for the current fold\n",
    "    X_train, X_test = features_scaled[train_index], features_scaled[test_index]\n",
    "    y_train, y_test = data.iloc[train_index]['School'], data.iloc[test_index]['School']\n",
    "    \n",
    "    # Perform similarity matching and evaluation for cosine similarity\n",
    "    cosine_similarity_scores, _ = compute_similarity_scores(X_train, 0)  # Target index is assumed to be 0\n",
    "    sorted_indices_cosine = sorted(range(len(cosine_similarity_scores)), key=lambda i: cosine_similarity_scores[i], reverse=True)\n",
    "    top_similar_schools_cosine = sorted_indices_cosine[1:6]  # Exclude the target school itself\n",
    "    \n",
    "    # Compute accuracy for cosine similarity\n",
    "    correct_predictions_cosine = sum(data.iloc[top_similar_schools_cosine]['School'].isin(y_test))\n",
    "    accuracy_cosine = correct_predictions_cosine / len(top_similar_schools_cosine)\n",
    "    cosine_similarity_accuracy.append(accuracy_cosine)\n",
    "    \n",
    "    # Perform similarity matching and evaluation for Euclidean distance\n",
    "    _, euclidean_distances = compute_similarity_scores(X_train, 0)  # Target index is assumed to be 0\n",
    "    sorted_indices_euclidean = sorted(range(len(euclidean_distances)), key=lambda i: euclidean_distances[i])\n",
    "    top_similar_schools_euclidean = sorted_indices_euclidean[1:6]  # Exclude the target school itself\n",
    "    \n",
    "    # Compute accuracy for Euclidean distance\n",
    "    correct_predictions_euclidean = sum(data.iloc[top_similar_schools_euclidean]['School'].isin(y_test))\n",
    "    accuracy_euclidean = correct_predictions_euclidean / len(top_similar_schools_euclidean)\n",
    "    euclidean_distance_accuracy.append(accuracy_euclidean)\n",
    "\n",
    "# Calculate average accuracy across all folds for cosine similarity\n",
    "average_accuracy_cosine = np.mean(cosine_similarity_accuracy)\n",
    "print(\"Average Accuracy for Cosine Similarity:\", average_accuracy_cosine)\n",
    "\n",
    "# Calculate average accuracy across all folds for Euclidean distance\n",
    "average_accuracy_euclidean = np.mean(euclidean_distance_accuracy)\n",
    "print(\"Average Accuracy for Euclidean Distance:\", average_accuracy_euclidean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5200883d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 similar schools to Great Hearts Academies - Anthem Prep using KNN:\n",
      "1. Great Hearts Academies - Chandler Prep\n",
      "2. Great Hearts Academies - Archway Veritas\n",
      "3. Great Hearts Academies - Veritas Prep\n",
      "4. Great Hearts Academies - North Phoenix Prep\n",
      "5. Basis Phoenix Central Primary\n",
      "\n",
      "\n",
      "Top 5 similar schools to Great Hearts Academies - Anthem Prep using SVM:\n",
      "1. University High School\n",
      "2. Sossaman Middle School\n",
      "3. Mesa Academy for Advanced Studies\n",
      "4. Camelback High School\n",
      "\n",
      "5. Paragon Science Academy\n",
      "\n",
      "Top 5 similar schools to Great Hearts Academies - Anthem Prep using Decision Trees:\n",
      "1. Central High School\n",
      "2. Central High School\n",
      "\n",
      "3. Boulder Creek High School\n",
      "4. Willow Canyon High School\n",
      "5. Imagine Prep Surprise\n"
     ]
    }
   ],
   "source": [
    "# Printing results for SVM, KNN & DT\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('Data_After_Transformation.csv')\n",
    "\n",
    "# Select features\n",
    "features = data[['Zip Code', 'Student Enrollment',\n",
    "                 'State Wide Assessment Results - 2023 : ELA (English Language Arts) : ALL ENROLLED - Minimally Proficient(%)',\n",
    "                 'State Wide Assessment Results - 2023 : ELA (English Language Arts) : ALL ENROLLED - Partially Proficient(%)',\n",
    "                 'State Wide Assessment Results - 2023 : ELA (English Language Arts) : ALL ENROLLED - Proficient(%)',\n",
    "                 'State Wide Assessment Results - 2023 : ELA (English Language Arts) : ALL ENROLLED - Highly Proficient(%)',\n",
    "                 'State Wide Assessment Results - 2023 All:MATH : ALL ENROLLED - Minimally Proficient(%)',\n",
    "                 'State Wide Assessment Results - 2023 All:MATH : ALL ENROLLED - Partially Proficient(%)',\n",
    "                 'State Wide Assessment Results - 2023 All:MATH : ALL ENROLLED - Proficient(%)',\n",
    "                 'State Wide Assessment Results - 2023 All:MATH : ALL ENROLLED - Highly Proficient(%)',\n",
    "                 'End of Year Promotion (%)']].values\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Initialize KNN model\n",
    "knn_model = NearestNeighbors(n_neighbors=6, algorithm='auto', metric='euclidean')\n",
    "knn_model.fit(features_scaled)\n",
    "\n",
    "# Initialize SVM model\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(features_scaled, data['School'])\n",
    "\n",
    "# Initialize Decision Tree model\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(features_scaled, data['School'])\n",
    "\n",
    "# Function to find similar schools using KNN\n",
    "def find_similar_schools_knn(target_school_index, data, features_scaled, knn_model, top_n=5):\n",
    "    # Find k-nearest neighbors\n",
    "    distances, indices = knn_model.kneighbors([features_scaled[target_school_index]])\n",
    "    \n",
    "    # Get the indices of similar schools\n",
    "    similar_school_indices = indices[0][1:]  # Exclude the target school itself\n",
    "    \n",
    "    # Get the names of similar schools\n",
    "    similar_schools = data.iloc[similar_school_indices]['School'].tolist()\n",
    "    \n",
    "    return similar_schools\n",
    "\n",
    "# Function to find similar schools using SVM\n",
    "def find_similar_schools_svm(target_school_index, data, features_scaled, svm_model, top_n=5):\n",
    "    # Get the decision function values for all schools\n",
    "    decision_function_values = svm_model.decision_function(features_scaled)\n",
    "    \n",
    "    # Calculate the distance of each school from the decision boundary\n",
    "    distances = abs(decision_function_values)\n",
    "    \n",
    "    # Sort indices based on distance (excluding the target school itself)\n",
    "    sorted_indices = distances.argsort()\n",
    "    similar_school_indices = sorted_indices[sorted_indices != target_school_index][:top_n]\n",
    "    \n",
    "    # Get the names of similar schools\n",
    "    similar_schools = data.iloc[similar_school_indices]['School'].tolist()\n",
    "    \n",
    "    return similar_schools\n",
    "\n",
    "# Function to find similar schools using Decision Trees\n",
    "def find_similar_schools_dt(target_school_index, data, features_scaled, dt_model, top_n=5):\n",
    "    # Get the feature values for the target school\n",
    "    target_school_features = [features_scaled[target_school_index]]\n",
    "    \n",
    "    # Predict the class probabilities for all schools\n",
    "    class_probabilities = dt_model.predict_proba(features_scaled)\n",
    "    \n",
    "    # Calculate the Euclidean distance between the target school and all other schools\n",
    "    distances = ((class_probabilities - dt_model.predict_proba(target_school_features))**2).sum(axis=1)\n",
    "    \n",
    "    # Sort indices based on distance (excluding the target school itself)\n",
    "    sorted_indices = distances.argsort()\n",
    "    similar_school_indices = sorted_indices[sorted_indices != target_school_index][:top_n]\n",
    "    \n",
    "    # Get the names of similar schools\n",
    "    similar_schools = data.iloc[similar_school_indices]['School'].tolist()\n",
    "    \n",
    "    return similar_schools\n",
    "\n",
    "# Example usage: Find top 5 similar schools for a given target school\n",
    "target_school_index = 1  # Index of the target school in the dataset\n",
    "target_school_name = data.loc[target_school_index, 'School']  # Get the name of the target school\n",
    "\n",
    "# Find similar schools using KNN\n",
    "similar_schools_knn = find_similar_schools_knn(target_school_index, data, features_scaled, knn_model)\n",
    "print(f\"Top 5 similar schools to {target_school_name} using KNN:\")\n",
    "for i, school in enumerate(similar_schools_knn, 1):\n",
    "    print(f\"{i}. {school}\")\n",
    "\n",
    "# Find similar schools using SVM\n",
    "similar_schools_svm = find_similar_schools_svm(target_school_index, data, features_scaled, svm_model)\n",
    "print(f\"\\nTop 5 similar schools to {target_school_name} using SVM:\")\n",
    "for i, school in enumerate(similar_schools_svm, 1):\n",
    "    print(f\"{i}. {school}\")\n",
    "\n",
    "# Find similar schools using Decision Trees\n",
    "similar_schools_dt = find_similar_schools_dt(target_school_index, data, features_scaled, dt_model)\n",
    "print(f\"\\nTop 5 similar schools to {target_school_name} using Decision Trees:\")\n",
    "for i, school in enumerate(similar_schools_dt, 1):\n",
    "    print(f\"{i}. {school}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "631550c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Buffer has wrong number of dimensions (expected 1, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 55\u001b[0m\n\u001b[1;32m     53\u001b[0m knn_model\u001b[38;5;241m.\u001b[39mfit(X_train)\n\u001b[1;32m     54\u001b[0m _, indices \u001b[38;5;241m=\u001b[39m knn_model\u001b[38;5;241m.\u001b[39mkneighbors(X_test)\n\u001b[0;32m---> 55\u001b[0m knn_predictions \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39miloc[indices[:, \u001b[38;5;241m1\u001b[39m:]]\u001b[38;5;241m.\u001b[39mmode(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m     56\u001b[0m accuracy_knn \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(knn_predictions \u001b[38;5;241m==\u001b[39m y_test\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[1;32m     57\u001b[0m knn_accuracy\u001b[38;5;241m.\u001b[39mappend(accuracy_knn)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:1103\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1100\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1102\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m-> 1103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_axis(maybe_callable, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:1647\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1645\u001b[0m \u001b[38;5;66;03m# a list of integers\u001b[39;00m\n\u001b[1;32m   1646\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like_indexer(key):\n\u001b[0;32m-> 1647\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_list_axis(key, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m   1649\u001b[0m \u001b[38;5;66;03m# a single integer\u001b[39;00m\n\u001b[1;32m   1650\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1651\u001b[0m     key \u001b[38;5;241m=\u001b[39m item_from_zerodim(key)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:1618\u001b[0m, in \u001b[0;36m_iLocIndexer._get_list_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1601\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1602\u001b[0m \u001b[38;5;124;03mReturn Series values by list or array of integers.\u001b[39;00m\n\u001b[1;32m   1603\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1615\u001b[0m \u001b[38;5;124;03m`axis` can only be zero.\u001b[39;00m\n\u001b[1;32m   1616\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1617\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1618\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_take_with_is_copy(key, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   1620\u001b[0m     \u001b[38;5;66;03m# re-raise with different error message\u001b[39;00m\n\u001b[1;32m   1621\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositional indexers are out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:3948\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[0;34m(self, indices, axis)\u001b[0m\n\u001b[1;32m   3940\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_with_is_copy\u001b[39m(\u001b[38;5;28mself\u001b[39m: NDFrameT, indices, axis: Axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NDFrameT:\n\u001b[1;32m   3941\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3942\u001b[0m \u001b[38;5;124;03m    Internal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[1;32m   3943\u001b[0m \u001b[38;5;124;03m    attribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3946\u001b[0m \u001b[38;5;124;03m    See the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[1;32m   3947\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3948\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_take(indices\u001b[38;5;241m=\u001b[39mindices, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m   3949\u001b[0m     \u001b[38;5;66;03m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n\u001b[1;32m   3950\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39m_get_axis(axis)\u001b[38;5;241m.\u001b[39mequals(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis(axis)):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:3932\u001b[0m, in \u001b[0;36mNDFrame._take\u001b[0;34m(self, indices, axis, convert_indices)\u001b[0m\n\u001b[1;32m   3924\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3925\u001b[0m         axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3926\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m indices\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   3927\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write()\n\u001b[1;32m   3928\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m is_range_indexer(indices, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m))\n\u001b[1;32m   3929\u001b[0m     ):\n\u001b[1;32m   3930\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 3932\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mtake(\n\u001b[1;32m   3933\u001b[0m     indices,\n\u001b[1;32m   3934\u001b[0m     axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_block_manager_axis(axis),\n\u001b[1;32m   3935\u001b[0m     verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   3936\u001b[0m     convert_indices\u001b[38;5;241m=\u001b[39mconvert_indices,\n\u001b[1;32m   3937\u001b[0m )\n\u001b[1;32m   3938\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_data)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/managers.py:963\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[0;34m(self, indexer, axis, verify, convert_indices)\u001b[0m\n\u001b[1;32m    960\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m maybe_convert_indices(indexer, n, verify\u001b[38;5;241m=\u001b[39mverify)\n\u001b[1;32m    962\u001b[0m new_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m--> 963\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreindex_indexer(\n\u001b[1;32m    964\u001b[0m     new_axis\u001b[38;5;241m=\u001b[39mnew_labels,\n\u001b[1;32m    965\u001b[0m     indexer\u001b[38;5;241m=\u001b[39mindexer,\n\u001b[1;32m    966\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m    967\u001b[0m     allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    968\u001b[0m     copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    969\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/managers.py:747\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[1;32m    740\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[1;32m    741\u001b[0m         indexer,\n\u001b[1;32m    742\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[1;32m    743\u001b[0m         only_slice\u001b[38;5;241m=\u001b[39monly_slice,\n\u001b[1;32m    744\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39muse_na_proxy,\n\u001b[1;32m    745\u001b[0m     )\n\u001b[1;32m    746\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 747\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    748\u001b[0m         blk\u001b[38;5;241m.\u001b[39mtake_nd(\n\u001b[1;32m    749\u001b[0m             indexer,\n\u001b[1;32m    750\u001b[0m             axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    751\u001b[0m             fill_value\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    752\u001b[0m                 fill_value \u001b[38;5;28;01mif\u001b[39;00m fill_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mfill_value\n\u001b[1;32m    753\u001b[0m             ),\n\u001b[1;32m    754\u001b[0m         )\n\u001b[1;32m    755\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[1;32m    756\u001b[0m     ]\n\u001b[1;32m    758\u001b[0m new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m    759\u001b[0m new_axes[axis] \u001b[38;5;241m=\u001b[39m new_axis\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/managers.py:748\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    740\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[1;32m    741\u001b[0m         indexer,\n\u001b[1;32m    742\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[1;32m    743\u001b[0m         only_slice\u001b[38;5;241m=\u001b[39monly_slice,\n\u001b[1;32m    744\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39muse_na_proxy,\n\u001b[1;32m    745\u001b[0m     )\n\u001b[1;32m    746\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    747\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 748\u001b[0m         blk\u001b[38;5;241m.\u001b[39mtake_nd(\n\u001b[1;32m    749\u001b[0m             indexer,\n\u001b[1;32m    750\u001b[0m             axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    751\u001b[0m             fill_value\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    752\u001b[0m                 fill_value \u001b[38;5;28;01mif\u001b[39;00m fill_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mfill_value\n\u001b[1;32m    753\u001b[0m             ),\n\u001b[1;32m    754\u001b[0m         )\n\u001b[1;32m    755\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[1;32m    756\u001b[0m     ]\n\u001b[1;32m    758\u001b[0m new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m    759\u001b[0m new_axes[axis] \u001b[38;5;241m=\u001b[39m new_axis\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/blocks.py:945\u001b[0m, in \u001b[0;36mBlock.take_nd\u001b[0;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[1;32m    942\u001b[0m     allow_fill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;66;03m# Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\u001b[39;00m\n\u001b[0;32m--> 945\u001b[0m new_values \u001b[38;5;241m=\u001b[39m algos\u001b[38;5;241m.\u001b[39mtake_nd(\n\u001b[1;32m    946\u001b[0m     values, indexer, axis\u001b[38;5;241m=\u001b[39maxis, allow_fill\u001b[38;5;241m=\u001b[39mallow_fill, fill_value\u001b[38;5;241m=\u001b[39mfill_value\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    949\u001b[0m \u001b[38;5;66;03m# Called from three places in managers, all of which satisfy\u001b[39;00m\n\u001b[1;32m    950\u001b[0m \u001b[38;5;66;03m#  these assertions\u001b[39;00m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ExtensionBlock):\n\u001b[1;32m    952\u001b[0m     \u001b[38;5;66;03m# NB: in this case, the 'axis' kwarg will be ignored in the\u001b[39;00m\n\u001b[1;32m    953\u001b[0m     \u001b[38;5;66;03m#  algos.take_nd call above.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/array_algos/take.py:117\u001b[0m, in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mtake(indexer, fill_value\u001b[38;5;241m=\u001b[39mfill_value, allow_fill\u001b[38;5;241m=\u001b[39mallow_fill)\n\u001b[1;32m    116\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(arr)\n\u001b[0;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/array_algos/take.py:162\u001b[0m, in \u001b[0;36m_take_nd_ndarray\u001b[0;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m    157\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(out_shape, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    159\u001b[0m func \u001b[38;5;241m=\u001b[39m _get_take_nd_function(\n\u001b[1;32m    160\u001b[0m     arr\u001b[38;5;241m.\u001b[39mndim, arr\u001b[38;5;241m.\u001b[39mdtype, out\u001b[38;5;241m.\u001b[39mdtype, axis\u001b[38;5;241m=\u001b[39maxis, mask_info\u001b[38;5;241m=\u001b[39mmask_info\n\u001b[1;32m    161\u001b[0m )\n\u001b[0;32m--> 162\u001b[0m func(arr, indexer, out, fill_value)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flip_order:\n\u001b[1;32m    165\u001b[0m     out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[0;32mpandas/_libs/algos_take_helper.pxi:2003\u001b[0m, in \u001b[0;36mpandas._libs.algos.take_2d_axis1_float64_float64\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Buffer has wrong number of dimensions (expected 1, got 2)"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('Data_After_Transformation.csv')\n",
    "\n",
    "# Select features\n",
    "features = data[['Zip Code', 'Student Enrollment',\n",
    "                 'State Wide Assessment Results - 2023 : ELA (English Language Arts) : ALL ENROLLED - Minimally Proficient(%)',\n",
    "                 'State Wide Assessment Results - 2023 : ELA (English Language Arts) : ALL ENROLLED - Partially Proficient(%)',\n",
    "                 'State Wide Assessment Results - 2023 : ELA (English Language Arts) : ALL ENROLLED - Proficient(%)',\n",
    "                 'State Wide Assessment Results - 2023 : ELA (English Language Arts) : ALL ENROLLED - Highly Proficient(%)',\n",
    "                 'State Wide Assessment Results - 2023 All:MATH : ALL ENROLLED - Minimally Proficient(%)',\n",
    "                 'State Wide Assessment Results - 2023 All:MATH : ALL ENROLLED - Partially Proficient(%)',\n",
    "                 'State Wide Assessment Results - 2023 All:MATH : ALL ENROLLED - Proficient(%)',\n",
    "                 'State Wide Assessment Results - 2023 All:MATH : ALL ENROLLED - Highly Proficient(%)',\n",
    "                 'End of Year Promotion (%)']].values\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "k = 5\n",
    "\n",
    "# Initialize KFold cross-validator\n",
    "kf = KFold(n_splits=k)\n",
    "\n",
    "# Initialize lists to store evaluation metrics\n",
    "svm_accuracy = []\n",
    "knn_accuracy = []\n",
    "dt_accuracy = []\n",
    "\n",
    "# Iterate over each fold\n",
    "for train_index, test_index in kf.split(features_scaled):\n",
    "    # Split data into training and testing sets for the current fold\n",
    "    X_train, X_test = features_scaled[train_index], features_scaled[test_index]\n",
    "    y_train, y_test = data.iloc[train_index]['School'], data.iloc[test_index]['School']\n",
    "    \n",
    "    # SVM\n",
    "    svm_model = SVC(kernel='linear')\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    accuracy_svm = svm_model.score(X_test, y_test)\n",
    "    svm_accuracy.append(accuracy_svm)\n",
    "    \n",
    "    # KNN\n",
    "    knn_model = NearestNeighbors(n_neighbors=6, algorithm='auto', metric='euclidean')\n",
    "    knn_model.fit(X_train)\n",
    "    _, indices = knn_model.kneighbors(X_test)\n",
    "    knn_predictions = data.iloc[indices[:, 1:]].mode(axis=1).values.flatten()\n",
    "    accuracy_knn = np.mean(knn_predictions == y_test.values)\n",
    "    knn_accuracy.append(accuracy_knn)\n",
    "    print(\"Indices shape:\", indices.shape)\n",
    "\n",
    "    \n",
    "    # Decision Tree\n",
    "    dt_model = DecisionTreeClassifier()\n",
    "    dt_model.fit(X_train, y_train)\n",
    "    accuracy_dt = dt_model.score(X_test, y_test)\n",
    "    dt_accuracy.append(accuracy_dt)\n",
    "\n",
    "# Calculate average accuracy across all folds for SVM\n",
    "average_accuracy_svm = np.mean(svm_accuracy)\n",
    "print(\"Average Accuracy for SVM:\", average_accuracy_svm)\n",
    "\n",
    "# Calculate average accuracy across all folds for KNN\n",
    "average_accuracy_knn = np.mean(knn_accuracy)\n",
    "print(\"Average Accuracy for KNN:\", average_accuracy_knn)\n",
    "\n",
    "# Calculate average accuracy across all folds for Decision Tree\n",
    "average_accuracy_dt = np.mean(dt_accuracy)\n",
    "print(\"Average Accuracy for Decision Tree:\", average_accuracy_dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d7a13a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
